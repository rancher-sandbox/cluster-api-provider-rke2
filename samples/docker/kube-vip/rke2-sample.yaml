apiVersion: v1
kind: Namespace
metadata:
  name: ${CABPR_NAMESPACE}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster 
metadata:
  namespace: ${CABPR_NAMESPACE}
  name: ${CLUSTER_NAME} 
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
      - 10.45.0.0/16
    services:
      cidrBlocks:
      - 10.46.0.0/16
    serviceDomain: cluster.local
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: RKE2ControlPlane
    name: ${CLUSTER_NAME}-control-plane
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: DockerCluster
    name: ${CLUSTER_NAME}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: DockerCluster
metadata:
  name: ${CLUSTER_NAME}
  namespace: ${CABPR_NAMESPACE}
---
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: RKE2ControlPlane
metadata:
  name: ${CLUSTER_NAME}-control-plane
  namespace: ${CABPR_NAMESPACE}
spec: 
  replicas: ${CABPR_CP_REPLICAS}
  agentConfig:
    version: ${KUBERNETES_VERSION}+rke2r1
  serverConfig:
    cni: calico
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: DockerMachineTemplate
    name: controlplane
  nodeDrainTimeout: 2m
  registrationMethod: "address"
  registrationAddress: "${REGISTRATION_VIP}"
  preRKE2Commands:
  - mkdir -p /var/lib/rancher/rke2/server/manifests/ && ctr images pull ghcr.io/kube-vip/kube-vip:v0.6.0 && ctr run --rm --net-host ghcr.io/kube-vip/kube-vip:v0.6.0 vip /kube-vip manifest daemonset --arp --interface $(ip -4 -j route list default | jq -r .[0].dev) --address ${REGISTRATION_VIP} --controlplane --leaderElection --taint --services --inCluster | tee /var/lib/rancher/rke2/server/manifests/kube-vip.yaml
  files:
  - path: /var/lib/rancher/rke2/server/manifests/kube-vip-rbac.yaml
    content: |
      apiVersion: v1
      kind: ServiceAccount
      metadata:
        name: kube-vip
        namespace: kube-system
      ---
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRole
      metadata:
        annotations:
          rbac.authorization.kubernetes.io/autoupdate: "true"
        name: system:kube-vip-role
      rules:
        - apiGroups: [""]
          resources: ["services", "services/status", "nodes", "endpoints"]
          verbs: ["list","get","watch", "update"]
        - apiGroups: ["coordination.k8s.io"]
          resources: ["leases"]
          verbs: ["list", "get", "watch", "update", "create"]
      ---
      kind: ClusterRoleBinding
      apiVersion: rbac.authorization.k8s.io/v1
      metadata:
        name: system:kube-vip-binding
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: system:kube-vip-role
      subjects:
      - kind: ServiceAccount
        name: kube-vip
        namespace: kube-system
    owner: root:root
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: DockerMachineTemplate
metadata:
  name: controlplane
  namespace: ${CABPR_NAMESPACE}
spec:
  template:
    spec: {} 
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  name: worker-md-0
  namespace: ${CABPR_NAMESPACE}
spec:
  clusterName: ${CLUSTER_NAME}
  replicas: ${CABPR_WK_REPLICAS}
  selector:
    matchLabels:
      cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
  template:
    spec:
      version: ${KUBERNETES_VERSION}
      clusterName: ${CLUSTER_NAME}
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1alpha1
          kind: RKE2ConfigTemplate
          name: ${CLUSTER_NAME}-agent
          namespace: ${CABPR_NAMESPACE}
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: DockerMachineTemplate
        name: worker
        namespace: ${CABPR_NAMESPACE}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: DockerMachineTemplate
metadata:
  name: worker
  namespace: ${CABPR_NAMESPACE}
spec:
  template:
    spec: {} 
---
apiVersion: bootstrap.cluster.x-k8s.io/v1alpha1
kind: RKE2ConfigTemplate
metadata:
  namespace: ${CABPR_NAMESPACE}
  name: ${CLUSTER_NAME}-agent
spec: 
  template:
    spec:
      agentConfig:
        version: ${KUBERNETES_VERSION}+rke2r1
